{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Model_1-tf-df & SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/bo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download 'wordnet'\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.stem import LancasterStemmer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Fetch the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the entire dataset.\n",
    "import load_20newsgroups\n",
    "\n",
    "texts_train = load_20newsgroups.texts_train\n",
    "labels_train = load_20newsgroups.labels_train\n",
    "\n",
    "texts_test = load_20newsgroups.texts_test\n",
    "labels_test = load_20newsgroups.labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data - lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a func for lemmatization \n",
    "# originally it contains stemming function, which was deleted due to too many mistakes incurred.\n",
    "def lemmatize(text_list):\n",
    "    lmtzer = WordNetLemmatizer()\n",
    "    #stemmer = LancasterStemmer()\n",
    "    new_texts = [] # list of list of words\n",
    "     \n",
    "    for list in text_list: # text is a list of words\n",
    "        new_text = '' # list of words\n",
    "        for word in list:\n",
    "            ld_wrd = lmtzer.lemmatize(word)\n",
    "            #sd_wrd = stemmer.stem(ld_wrd)\n",
    "            new_text += ld_wrd\n",
    "            new_text += ' '\n",
    "        new_texts.append(new_text)\n",
    "    return new_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.45084500312805"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization of the original corpus\n",
    "time0 = time.time()\n",
    "texts_train_ls= lemmatize([text.split() for text in texts_train])\n",
    "texts_test_ls = lemmatize([text.split() for text in texts_test])\n",
    "time.time() - time0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing) Subject: WHAT car is this!? Nntp-Posting-Host: rac3.wam.umd.edu Organization: University of Maryland, College Park Lines: 15 I wa wondering if anyone out there could enlighten me on this car I saw the other day. It wa a 2-door sport car, looked to be from the late 60s/ early 70s. It wa called a Bricklin. The door were really small. In addition, the front bumper wa separate from the rest of the body. This is all I know. If anyone can tellme a model name, engine specs, year of production, where this car is made, history, or whatever info you have on this funky looking car, please e-mail. Thanks, - IL ---- brought to you by your neighborhood Lerxst ---- \""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_train_ls[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "def text_clf(texts,targets,vect,clf,params):\n",
    "    time0 =time.time()\n",
    "    model = Pipeline([('vect',vect),\n",
    "                      ('clf',clf)])\n",
    "    \n",
    "    gsc_clf = GridSearchCV(model,params,cv = 5,scoring = 'accuracy')\n",
    "    gsc_clf.fit(texts,targets)\n",
    "    time_train = time.time()-time0\n",
    "    return gsc_clf.best_estimator_,time_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal value in the range of 0.1~1, step being 0.1, for 'vect__max_df'\n",
    "# find optimal value in the range of [1e-4,1e-3,1e-2] for 'clf__alpha'\n",
    "vect = TfidfVectorizer(analyzer='word')\n",
    "clf = SGDClassifier(max_iter = 5,random_state = 0)\n",
    "params = {'vect__max_df':np.arange(0.1,1.,0.1),'vect__max_features':np.arange(10000,100000,10000),'clf__alpha':[1e-4,1e-3,1e-2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model,time_train = text_clf(texts_train_ls,labels_train,vect,clf,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost for fitting the model: 13229.38 s\n",
      "The value of clf__alpha is: 0.0001\n",
      "The value of vect__max_df is: 0.1\n",
      "The value of vect__max_features is: 90000\n"
     ]
    }
   ],
   "source": [
    "print (\"Time cost for fitting the model: %.2f s\" %time_train)\n",
    "print (\"The value of clf__alpha is:\",optimal_model.get_params()['clf__alpha'])\n",
    "print (\"The value of vect__max_df is:\",optimal_model.get_params()['vect__max_df'])\n",
    "print (\"The value of vect__max_features is:\",optimal_model.get_params()['vect__max_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost for making predictions:4.01 s\n",
      "Accuracy score:0.8518\n"
     ]
    }
   ],
   "source": [
    "time0 = time.time()\n",
    "preds = optimal_model.predict(texts_test_ls)\n",
    "time_test = time.time()-time0\n",
    "acc = np.mean(labels_test==preds)\n",
    "print(\"Time cost for making predictions:%.2f s\" %time_test)\n",
    "print (\"Accuracy score:%.4f\"%acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_2 = f1_score(labels_test,preds,average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8518321826872013\n"
     ]
    }
   ],
   "source": [
    "print(f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
test
